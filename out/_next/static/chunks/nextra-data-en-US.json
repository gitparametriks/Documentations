{"/IoT-Dashboard-Backend/database-relational-diagram":{"title":"Database Relational Diagram","data":{"":"This document details the structure and relationships of the entities within the Facility Management Database.","database-relational-diagram#Database Relational Diagram":"","entities-summary#Entities Summary":"Entity\tPrimary Key (PK)\tForeign Key (FK)\tDescription\tSENSORS\tsensor_id\tfacility_id (links to Facilities)\tStores sensor details, including type, installation date, and operational status.\tFACILITIES\tfacility_id\t-\tInformation about each facility, including location, manager, and digital twin status.\tALERTS\talert_id\tfacility_id, sensor_id\tTracks alerts generated by sensors, linked to specific facilities.\tRISKS\trisk_id\tfacility_id\tInformation on identified risks, including type, impact level, and resolution status.\tACTIONS\taction_id\trisk_id\tDescribes actions taken to address risks, including action type and description.\tCLAIMS\tclaim_id\t-\tHolds claim-related data, including predicted and actual claim values.\tSAFETYCHECKS\tcheck_id\tfacility_id\tRecords safety inspections, detailing inspector, type, and result status.\tMAINTENANCETASKS\ttask_id\trisk_id, facility_id\tDetails maintenance tasks performed to address risks, including severity and status.\tINCIDENTS\tincident_id\tfacility_id\tDocuments incidents at facilities, including severity and status.\tSENSORDATA\t-\tsensor_id\tSensor data logs, recording values like humidity, temperature, and CO2 at specific timestamps.\tANOMALIES\tanomaly_id\tsensor_id\tStores details of detected anomalies in sensor data, including type and timestamp.\tEXPENSES\texpense_id\tsensor_id\tLogs expenses associated with sensors, including expense amount and date.\tSAVINGS\tsavings_id\tsensor_id\tTracks savings generated by sensors, including savings amount and date.","entity-attributes#Entity Attributes":"","sensors#SENSORS":"sensor_id (PK): Unique identifier for each sensor.\nfacility_id (FK): Links to the facility where the sensor is installed.\nsensor_type: Type of sensor.\ninstallation_date: Date of installation.\nstatus: Operational status of the sensor.","facilities#FACILITIES":"facility_id (PK): Unique identifier for each facility.\nfacility_name: Name of the facility.\nlocation: Location of the facility.\nstatus: Operational status.\nmanager_name: Manager responsible.\nlast_inspection_date: Date of last inspection.\ndigital_twin_status: Status of the digital twin.","alerts#ALERTS":"alert_id (PK): Unique identifier for each alert.\nstatus: Current alert status.\nfacility_id (FK): Linked facility.\nsensor_id (FK): Sensor that triggered the alert.","risks#RISKS":"risk_id (PK): Unique identifier.\nrisk_type: Category/type.\nfacility_id (FK): Affected facility.\nstatus: Status of the risk.\nimpact_level: Severity level.\ndate_reported: Date identified.\ndate_addressed: Date resolved (if applicable).","actions#ACTIONS":"action_id (PK): Unique identifier.\nrisk_id (FK): Linked risk.\naction_type: Type of action.\naction_description: Detailed description.\naction_date: Date performed.","claims#CLAIMS":"claim_id (PK): Unique identifier.\npredicted_claim: Estimated amount.\nactual_claim: Actual amount processed.\nclaim_without_parametriks: Unadjusted claim.\nclaim_month: Month pertaining to claim.","safetychecks#SAFETYCHECKS":"check_id (PK): Unique identifier.\ninspector_name: Inspector name.\ninspection_type: Type of inspection.\nstatus: Result status.\nfacility_id (FK): Facility inspected.","maintenancetasks#MAINTENANCETASKS":"task_id (PK): Unique identifier.\nrisk_id (FK): Associated risk.\nincident: Prompting incident.\nseverity: Incident severity.\nstatus: Current status.\ndate: Date of the task.\nfacility_id (FK): Facility where task occurred.","incidents#INCIDENTS":"incident_id (PK): Unique identifier.\nincident: Description.\nseverity: Incident severity.\nstatus: Current status.\ndate: Occurrence date.\nfacility_id (FK): Facility affected.","sensordata#SENSORDATA":"sensor_id (FK): Associated sensor.\ntimestamp: Data capture time.\nhumidity: Humidity level.\ntemperature: Temperature reading.\nCO2: CO2 level.","anomalies#ANOMALIES":"anomaly_id (PK): Unique identifier.\nsensor_id (FK): Sensor detecting anomaly.\nanomaly_type: Type of anomaly.\ntimestamp: Detection time.","expenses#EXPENSES":"expense_id (PK): Unique identifier.\nsensor_id (FK): Related sensor.\nexpense_amount: Cost amount.\nexpense_date: Date incurred.","savings#SAVINGS":"savings_id (PK): Unique identifier.\nsensor_id (FK): Related sensor.\nsavings_amount: Amount saved.\nsavings_date: Date recorded.","relationships-overview#Relationships Overview":"erDiagram\nFACILITIES {\nint Facility_ID PK\nstring Facility_Name\nstring Location\nstring Status\nstring Manager_Name\nstring Digital_Twin_Status\nstring Digital_Twin_Link\nstring Risk_Level\n}\n\nSENSORS {\nint Sensor_ID PK\nint Facility_ID FK\ndate Deployment_Date\nfloat Expense\nstring Status\nfloat Sensor_Value\nstring Sensor_Type\nstring Sensor_Unit\n}\n\nRISKS {\nint Risk_ID PK\nint Facility_ID FK\nstring Severity\nstring Risk_Type\ndate Date_of_Discovery\nstring Mitigation_Status\n}\n\nCLAIMS {\nint Claim_ID PK\nfloat Actual_Claim_Amount\nfloat Predicted_Claim_Amount\n}\n\nINCIDENTS {\nint Incident_ID PK\nint Facility_ID FK\nstring Incident_Type\nstring Severity\ndate Date\n}\n\nSAFETY_CHECKS {\nint Check_ID PK\nint Facility_ID FK\nstring Inspector_Name\nstring Inspection_Type\nstring Status\ndate Date_Of_Check\n}\n\nMAINTENANCE_TASKS {\nint Task_ID PK\nint Facility_ID FK\nint Risk_ID FK\nint Incident_ID FK\nstring Task_Type\nstring Incident\nstring Severity\nstring Status\ndate Date\n}\n\nFACILITIES ||--o{ SENSORS : \"has\"\nFACILITIES ||--o{ RISKS : \"has\"\nFACILITIES ||--o{ INCIDENTS : \"has\"\nFACILITIES ||--o{ MAINTENANCE_TASKS : \"has\"\nFACILITIES ||--o{ SAFETY_CHECKS : \"has\"\n\nSAFETY_CHECKS ||--o{  RISKS: \"can generate\"\n\nMAINTENANCE_TASKS ||--o{ RISKS : \"can mitigate / reduce\"\n\nRISKS ||--o| CLAIMS : \"generates predicted\"\nRISKS ||--o{ MAINTENANCE_TASKS : \"can generate (preventive / mitigative)\"\nRISKS ||--o{ INCIDENTS : \"can result in\"\n\nINCIDENTS ||--o| CLAIMS : \"can generate\"\nINCIDENTS ||--o{ MAINTENANCE_TASKS : \"can generate (reactive)\""}},"/IoT-Dashboard-Backend/machine-learning-assisted-data-transformation-for-insurance-platform":{"title":"Machine Learning-Assisted Data Transformation for Insurance Platform","data":{"":"This document outlines the machine learning process that transforms client-provided insurance data into a structured format aligned with our Database Relational Diagram. Leveraging Large Language Models (LLMs) and advanced machine learning algorithms, the platform standardizes and enriches raw data from varied sources for seamless integration.","overview#Overview":"","client-data#Client Data":"Clients or insurers may provide insurance data in various formats, primarily in CSV files and associated text documents that describe the CSV structure. These files often lack a standard format, necessitating a flexible, automated process for understanding and transforming data.","transformation-objectives#Transformation Objectives":"Data Understanding: Interpret client data structures, labels, and descriptions using LLMs.\nAlgorithm Selection: Use LLMs trained on insurance, mathematics, and statistics knowledge to suggest the best machine learning algorithms for data transformation.\nData Standardization: Transform data into a unified format according to the Database Relational Diagram schema.\nIntegration: Store transformed data into the platform's database, ready for insights and predictive analytics.","transformation-process#Transformation Process":"","step-1-data-ingestion#Step 1: Data Ingestion":"Format Compatibility: Accept data in multiple formats (e.g., CSV, Excel) and include metadata from descriptive text files.\nInitial Storage: Store the raw data in a secure and accessible environment on the platform.","step-2-data-interpretation-using-llm#Step 2: Data Interpretation Using LLM":"Schema Analysis: The LLM, using natural language processing, interprets the data schema, column headers, and any descriptive information.\nEntity Mapping: Matches fields from client data to relevant entities in the Database Relational Diagram (e.g., FACILITIES, SENSORS, RISKS).","step-3-algorithm-selection#Step 3: Algorithm Selection":"The LLM leverages its training in statistical and machine learning methodologies to recommend algorithms tailored for the transformation task, including:\nData Cleaning: Identifies and corrects inconsistencies (e.g., missing values, outliers).\nNormalization and Standardization: Aligns numerical and categorical data to the platform’s schema.\nText Classification: Classifies unstructured text fields into predefined categories (e.g., risk_type in RISKS).\nAnomaly Detection: Suggests models to identify anomalies, which can be mapped to ANOMALIES in the database.","step-4-data-transformation#Step 4: Data Transformation":"Mapping and Standardization: Applies transformations based on the selected algorithms to convert raw data into a standard format.\nEntity Relationships: Establishes relationships across entities (e.g., linking SENSORS to FACILITIES) as outlined in the Database Relational Diagram.","step-5-database-insertion#Step 5: Database Insertion":"The transformed data is now in a schema-compliant format, ready to be inserted into the database.\nError Handling: Any inconsistencies during insertion are logged for review.","step-6-continuous-learning#Step 6: Continuous Learning":"Feedback from data analysts is used to fine-tune the machine learning algorithms, enhancing future transformations for accuracy and efficiency.","transformation-flow-diagram#Transformation Flow Diagram":"","benefits-of-machine-learning-integration#Benefits of Machine Learning Integration":"Automated Data Understanding: The LLM’s ability to interpret schema and descriptions simplifies onboarding for new clients.\nIntelligent Transformation: Algorithm recommendations by LLMs ensure data is efficiently transformed and standardized.\nEnhanced Accuracy: Machine learning reduces manual errors and ensures data integrity.\nScalability: The platform can easily scale to handle data from multiple clients with varied formats.\n\nMachine learning enables efficient, accurate, and scalable data integration, providing clients with immediate access to analytics and insights on the platform."}},"/IoT-Dashboard-Frontend/about-project":{"title":"About the Project","data":{"":"The IoT Dashboard Frontend is a feature-rich, responsive web application built by Parametriks to provide an intuitive interface for monitoring and managing IoT devices. The dashboard offers real-time data visualization and control functionalities to optimize and monitor IoT operations efficiently.","key-features#Key Features":"Real-time monitoring of IoT devices.\nData visualization for various metrics including claims, risks, and sensor data.\nAWS Cognito integration for authentication and user management.\nComprehensive analytics for clients and insurers."}},"/IoT-Dashboard-Frontend/getting-started":{"title":"Getting Started","data":{"":"Follow these instructions to set up and run the project locally.","prerequisites#Prerequisites":"Node.js and npm\nnpm install npm@latest -g","installation#Installation":"Clone the repository\ngit clone https://github.com/parametriks/iot-dashboard-frontend.git\n\nNavigate to the project directory\ncd iot-dashboard-frontend\n\nInstall NPM packages\nnpm install"}},"/NOC-Intern/what-to-know":{"title":"What to Know","data":{"":"Welcome to Parametriks! To get the most out of our documentation and better understand our mission, we encourage you to familiarize yourself with our company, our key team members, and the technologies we use.","company-information#Company Information":"Website: Parametriks Main Website","key-team-members#Key Team Members":"","thomas-fayon#Thomas Fayon":"Founder & CEO\nA passionate tech enthusiast and born innovator, Thomas has co-founded several startups, including Shift Technology. His experience and vision drive Parametriks' mission to innovate in the insurance sector through cutting-edge IoT and predictive analytics technology.\nThomas is the guy to go to for new ideas, clarification of business goals and pricing strategies, and market postion. All the busines related knowledge and connections to insurance companies, he would be the man.","françoise-carli#Françoise Carli":"Chairwoman & Strategist\nWith a remarkable background as the ex-CEO of Zurich Insurance and a current board member of various captives and insurance companies, Françoise brings global leadership and deep industry expertise to Parametriks. Her strategic insights shape our direction and guide our growth.\nFrançoise would be the lady you rarely see and talk to. However, when you do calls with her, she is full of insights and experience. So please do take notes and internalise what she shares.","shivang-gupta#Shivang Gupta":"CEO Asia\nShivang's strong foundation in computer science, data science, and machine learning is instrumental in spearheading Parametriks' expansion in the Asian market. His technical expertise ensures that we deliver high-quality, scalable solutions to our clients.\nShivangg is in charge of the India market as of my time. He is dealing with the business aspects but has deep understanding of tech and can help you with the frontend. But he is busy too so please do help out more.","zhan-yakun#Zhan Yakun":"Managing Director\nWith a solid engineering background and a passion for business, Zhan drives innovation, operational excellence, and strategic growth at Parametriks. His leadership is pivotal in aligning our technical and business goals.\nYakun is someone you would talk to less as well. I have not had any interactions with her til today but yeah. FYI!","understanding-parametriks#Understanding Parametriks":"To fully engage with what Parametriks does, here are a few steps to help you get started:\nRead up on Parametriks' Tech Stack: Our solutions are built using modern technologies like Next.js, AWS, and other data visualization libraries. Gaining familiarity with these will help you understand how we build and deploy our applications.\nLearn About AWS Services: AWS forms a core part of our infrastructure. Understand key services like:\nAWS Cognito for authentication\nAWS IoT for device management\nAWS Bedrock for Retrieval Augmented Generation (RAG)\nAWS Lambda for serverless computing\nAWS IAM for policy an management\nAWS Sagemaker for building, training, and deploying machine learning models\nAWS S3 for scalable object storage\nAWS DynamoDB for key-value and document database with single-digit millisecond performance\n\n\nDive into the Documentation: Explore our documentation to get a comprehensive view of our projects, solutions, and the architecture we use. You’ll find detailed guides on how our systems integrate with IoT devices and how our algorithms optimize insurance processes.\n\nBy learning more about these areas, you’ll be better equipped to understand and engage with Parametriks' innovative solutions."}},"/":{"title":"Parametriks","data":{"":"Welcome to the official documentation for Parametriks. Parametriks is a B2B startup dedicated to transforming the insurance industry by helping insurers lower their insurance payouts through advanced risk mitigation and claims reduction strategies. We leverage predictive algorithms and cutting-edge IoT technology to achieve these outcomes.","our-mission#Our Mission":"At Parametriks, we aim to:\nReduce insurance payouts: By analyzing and predicting risk factors using IoT devices, we empower clients to take proactive measures to reduce their risks.\nOptimize premium pricing: By understanding the actions clients take to mitigate risks, insurers can adjust and price insurance premiums more accurately, ultimately lowering them.","what-we-do#What We Do":"Parametriks integrates with various IoT devices, such as CCTV systems and environmental sensors, to gather data that provides insights into the risk profiles of buildings and other insured assets. Our solutions include:\nCCTV Integration: Monitoring and analyzing video data to detect potential hazards and identify risk patterns.\nSensor Data Analysis: Using sensors to monitor environmental conditions (e.g., temperature, humidity, motion) and provide real-time alerts to mitigate risks like fire, flooding, or unauthorized access.\n\nBy managing risk dynamically and offering data-driven insights, we help insurers and their clients create safer environments, leading to fewer claims and more optimized insurance products.Explore the documentation to learn more about our solutions, integration processes, and how Parametriks can help your business."}},"/NOC-Intern/about-me":{"title":"About Me","data":{"":"Hello! I'm Javian Ng, a passionate machine learning engineer and software engineer previously working (if you see this and you are the next intern, i am likely gone already) at Parametriks, a startup focused on leveraging IoT technology and predictive algorithms to revolutionize the insurance industry.This Documentation page was crafted by me, and is a project that started on 25 October 2024. It should be relatively easy to follow along and guide you along on what you need to do as an intern here.\nTake note that my position then was a software engineer and machine learning engineer and so some of the details might not be relevant to you if you are not taking on the same role.","connect-with-me#Connect with Me":"LinkedIn: Javian Ng\nGitHub: Javian's GitHub"}}}